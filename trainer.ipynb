{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0281d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d362bc0",
   "metadata": {},
   "source": [
    "### Make sure you have a folder named \"mnist\" and it contains \"mnist_test.csv\" and \"mnist_train.csv\" from\n",
    "\n",
    "https://git-disl.github.io/GTDLBench/datasets/mnist_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f21168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset csv into a torch dataset class\n",
    "# Lets you use dataloader\n",
    "class MNISTCSVDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        with open(csv_file, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                label = int(row[0])\n",
    "                pixels = np.array(row[1:], dtype=np.float32) / 255.0  # normalize\n",
    "                self.data.append(pixels)\n",
    "                self.labels.append(label)\n",
    "\n",
    "        self.data = np.array(self.data).reshape(-1, 1, 28, 28)  # reshape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx])\n",
    "        return x, y\n",
    "    \n",
    "trainingSet = MNISTCSVDataset('mnist/mnist_train.csv')\n",
    "testingSet = MNISTCSVDataset('mnist/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56744fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set size: 60000\n",
      "Testing Set size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set size: {len(trainingSet)}\")\n",
    "print(f\"Testing Set size: {len(testingSet)}\")\n",
    "# print(trainingSet[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d5bc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=0)  # 8x26x26 No padding, stride=1\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(8 * 26 * 26, 10)  # 28x28 input â†’ 26x26 conv output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model: nn.Module, loader, epochs=5):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train() # Set to train mode\n",
    "    for epoch in range(epochs):\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        acc = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Accuracy: {acc:.2f}%, F1 Score: {f1:.4f}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsFolder = 'weights'\n",
    "def export_weights(model):\n",
    "    state = model.state_dict()\n",
    "    conv_w = state['conv.weight'].cpu().numpy()  # shape (8,1,3,3)\n",
    "    conv_b = state['conv.bias'].cpu().numpy()    # shape (8,)\n",
    "    fc_w   = state['fc.weight'].cpu().numpy()    # shape (10,5408)\n",
    "    fc_b   = state['fc.bias'].cpu().numpy()      # shape (10,)\n",
    "\n",
    "    np.save(f\"{weightsFolder}/conv_weight.npy\", conv_w)\n",
    "    np.save(f\"{weightsFolder}/conv_bias.npy\", conv_b)\n",
    "    np.save(f\"{weightsFolder}/fc_weight.npy\", fc_w)\n",
    "    np.save(f\"{weightsFolder}/fc_bias.npy\", fc_b)\n",
    "    print(\"Weights exported as .npy files.\")\n",
    "    \n",
    "def save_as_c_array(npy_file, var_name, output_file):\n",
    "    arr = np.load(f\"{weightsFolder}/{npy_file}\")\n",
    "    flat = arr.flatten()\n",
    "\n",
    "    with open(f\"{weightsFolder}/{output_file}\", \"w\") as f:\n",
    "        f.write(f\"// {arr.shape}\\n\")\n",
    "        f.write(f\"float {var_name}[{len(flat)}] = {{\\n\")\n",
    "        for i, val in enumerate(flat):\n",
    "            f.write(f\"{val}f, \")\n",
    "            if (i + 1) % 8 == 0:\n",
    "                f.write(\"\\n\")\n",
    "        f.write(\"};\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15f40e",
   "metadata": {},
   "source": [
    "# DON'T RUN THIS UNLESS U WANT TO RETRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b79d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Accuracy: 91.67%, F1 Score: 0.9159, Loss: 0.1240\n",
      "Epoch 2/25, Accuracy: 96.66%, F1 Score: 0.9665, Loss: 0.0200\n",
      "Epoch 3/25, Accuracy: 97.64%, F1 Score: 0.9763, Loss: 0.0305\n",
      "Epoch 4/25, Accuracy: 98.05%, F1 Score: 0.9804, Loss: 0.0349\n",
      "Epoch 5/25, Accuracy: 98.31%, F1 Score: 0.9831, Loss: 0.1221\n",
      "Epoch 6/25, Accuracy: 98.53%, F1 Score: 0.9853, Loss: 0.0146\n",
      "Epoch 7/25, Accuracy: 98.75%, F1 Score: 0.9874, Loss: 0.0302\n",
      "Epoch 8/25, Accuracy: 98.91%, F1 Score: 0.9890, Loss: 0.0893\n",
      "Epoch 9/25, Accuracy: 99.05%, F1 Score: 0.9905, Loss: 0.0179\n",
      "Epoch 10/25, Accuracy: 99.13%, F1 Score: 0.9913, Loss: 0.0802\n",
      "Epoch 11/25, Accuracy: 99.24%, F1 Score: 0.9924, Loss: 0.0082\n",
      "Epoch 12/25, Accuracy: 99.36%, F1 Score: 0.9936, Loss: 0.0074\n",
      "Epoch 13/25, Accuracy: 99.43%, F1 Score: 0.9943, Loss: 0.0023\n",
      "Epoch 14/25, Accuracy: 99.49%, F1 Score: 0.9949, Loss: 0.0075\n",
      "Epoch 15/25, Accuracy: 99.57%, F1 Score: 0.9957, Loss: 0.0052\n",
      "Epoch 16/25, Accuracy: 99.63%, F1 Score: 0.9963, Loss: 0.0082\n",
      "Epoch 17/25, Accuracy: 99.66%, F1 Score: 0.9966, Loss: 0.0094\n",
      "Epoch 18/25, Accuracy: 99.72%, F1 Score: 0.9972, Loss: 0.0010\n",
      "Epoch 19/25, Accuracy: 99.75%, F1 Score: 0.9975, Loss: 0.0034\n",
      "Epoch 20/25, Accuracy: 99.81%, F1 Score: 0.9981, Loss: 0.0009\n",
      "Epoch 21/25, Accuracy: 99.78%, F1 Score: 0.9978, Loss: 0.0003\n",
      "Epoch 22/25, Accuracy: 99.84%, F1 Score: 0.9984, Loss: 0.0107\n",
      "Epoch 23/25, Accuracy: 99.86%, F1 Score: 0.9986, Loss: 0.0012\n",
      "Epoch 24/25, Accuracy: 99.89%, F1 Score: 0.9989, Loss: 0.0003\n",
      "Epoch 25/25, Accuracy: 99.88%, F1 Score: 0.9987, Loss: 0.0274\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(trainingSet, batch_size=64, shuffle=True)\n",
    "\n",
    "model = cnn().to(device) # Move to GPU if possible\n",
    "train_model(model, dataloader, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26053cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights exported as .npy files.\n"
     ]
    }
   ],
   "source": [
    "export_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8af2b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"weights/model_weights.pth\")\n",
    "save_as_c_array(\"conv_weight.npy\", \"conv_weights\", \"conv_weights.h\")\n",
    "save_as_c_array(\"conv_bias.npy\", \"conv_biases\", \"conv_biases.h\")\n",
    "save_as_c_array(\"fc_weight.npy\", \"fc_weights\", \"fc_weights.h\")\n",
    "save_as_c_array(\"fc_bias.npy\", \"fc_biases\", \"fc_biases.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5495445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61435\\AppData\\Local\\Temp\\ipykernel_13664\\230626830.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"weights/model_weights.pth\").to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation: Accuracy = 9782/10000 97.82%, F1 Score = 0.9780\n"
     ]
    }
   ],
   "source": [
    "# Testing on the test data set\n",
    "model = torch.load(\"weights/model_weights.pth\").to(device)\n",
    "model.eval()\n",
    "trainLoader = DataLoader(testingSet, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # disable gradient tracking\n",
    "    for inputs, labels in trainLoader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        preds = probabilities.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Test set evaluation: Accuracy = {correct}/{total} {accuracy:.2f}%, F1 Score = {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca47ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15180436 -0.79033625 -0.1798562   0.00154718 -0.2145303  -0.07125219\n",
      " -0.01330574  0.13734898]\n"
     ]
    }
   ],
   "source": [
    "# Examining model weights and biases\n",
    "state = model.state_dict()\n",
    "conv_w = state['conv.weight'].cpu().numpy()  # shape (8,1,3,3)\n",
    "conv_b = state['conv.bias'].cpu().numpy()    # shape (8,)\n",
    "fc_w   = state['fc.weight'].cpu().numpy()    # shape (10,5408)\n",
    "fc_b   = state['fc.bias'].cpu().numpy()      # shape (10,)\n",
    "\n",
    "print(conv_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
